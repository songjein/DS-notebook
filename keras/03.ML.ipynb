{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝에 대한 전반적인 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 분류\n",
    "- 지도 학습(supervised learning)\n",
    "    - Sequence Generation ; 사진 캡션\n",
    "    - Syntax Tree Prediction ; 문장에 대한 구문 트리\n",
    "    - Object Detection ; 사진 분류 혹은 물체 경계 좌표 벡터 회귀로 예측\n",
    "    - Image Segmentation ; 픽셀 단위로 특정 물체 마스킹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비지도 학습\n",
    "    - 데이터 시각화, 압축, 노이즈 제거 또는 상관관계 얻기\n",
    "    - Dimensionality Reduction\n",
    "    - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자기 지도 학습(self-supervised learning)\n",
    "    - 학습 과정에 사람이 개입하지 않는 지도 학습\n",
    "    - Autoencoder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 강화 학습(Reinforcement learning)\n",
    "    - 에이전트는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가\n",
    "- 머신러닝의 목표, 처음 본 데이터에 대해 잘 동작하는 '일반화'된 모델 얻기\n",
    "    - Overfitting\n",
    "    - Train, Validation, Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련, 검증, 테스트 세트\n",
    "- 검증 데이터가 있는 이유\n",
    "    - hyperparameter(레이어 수, 유닛 수, ...)를 튜닝하기 위해서\n",
    "    - but 이 과정에서 검증 데이터에 Overfitting 될 수 있기 때문에\n",
    "        - 정보 누설(Information Leak) ; 검증 세트의 모델 성능에 기반해서 hyperparams 수정할 때마다, 검증 데이터에 관한 정보가 모델로 새는 것\n",
    "    - Test Set을 따로 둠\n",
    "- 데이터가 적을 경우엔 hold-out validation, K-fold cross-validation, iterated K-fold cross-validation(셔플링 사용)\n",
    "    - Hold-out Validation\n",
    "        - 그냥 특정 비율로 Train데이터와 Val데이터 나눠서 튜닝 후에 np.concatenate으로 합쳐서 최종 트레이닝\n",
    "        - 데이터가 적을 때 샘플이 전체 데이터를 통계적으로 대표하지 못할 수 \n",
    "    - K-fold Cross Validation\n",
    "        - K개의 분할로 나누고, i번째 fold(i <= k)를 Val데이터로 삼아 튜닝\n",
    "        - 데이터 분할에 따라 모델 성능 편차 클 때 좋음\n",
    "    - Iterated K-fold Cross Validation\n",
    "        - 그냥 K분할 나누기 전에 shuffle까지 해서 K-fold CV 자체를 i번 추가 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "- 훈련 세트, 테스트 세트는 전체 데이터를 대표할 수 있어야 함\n",
    "    - shuffle 정도는 무조건 하고 시작\n",
    "- 시간의 방향\n",
    "    - 과거로 부터 미래를 예측하려 할 때 무작위로 섞으면 절대 안됨\n",
    "    - 테스트 셋은 무조건 트레이닝 셋의 미래여야함\n",
    "- 데이터 중복은 당연히 없어야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "- 벡터화(vectorization)\n",
    "    - 뉴럴넷에서 모든 입력과 타겟은 부동 소수점 데이터로 이루어진 텐서! (특정 경우에는 정수)\n",
    "    - 처리에야 할 대상이 무엇이든 텐서로 변환\n",
    "- 정규화(normalization)\n",
    "    - 이미지 분류 할 때, 0~255 사이의 정수 데이터를 float으로 바꾸고 /255 해서 0~1사이의 부동 소수점 값으로 바꾸었음\n",
    "    - 주택 가격 예측 예제에선 각 피쳐들이 범위가 제각각 -> 각각 정규화해서 평균이 0이고 표준편차가 1이 되도록(standardization;표준화) 함\n",
    "        - 일반적으로 네트워크의 가중치 초깃값 보다 훨씬 큰 수나 균일하지 않은 데이터(피쳐 간에)를 뉴럴넷에 주입하는 것은 위험\n",
    "            - 업데이트할 그래디언트가 커져 네트워크가 수렴하기 힘들게 만듬\n",
    "            - 따라서 각 특성별로 평균이 0이 되도록 정규화 하고, 표준편차가 1이 되도록 정규화한다.\n",
    "            ```py\n",
    "            x -= x.mean(axis=0)\n",
    "            x /= x.std(axis=0)\n",
    "            ```\n",
    "- 누락된 값\n",
    "    - 일반적으로 뉴럴넷에서 0이 사전에 정의된 의미 있는 값이 아니라면\n",
    "    - 누락된 값을 0으로 입력 (네트워크가 0 = 누락 이라는 것을 학습하면 이 값을 무시)\n",
    "    - 트레이닝 데이터에 누락이 없지만 미래에 있을 수 있다면, 고의로 포함시켜 트레이닝 해야함\n",
    "    - 누락된 값을 평균 혹을 중간 값으로 대체하기도 함 (이 경우 해당 값을 기록하고 테스트 때 활용)\n",
    "    - 누락된 값이 덜 중요하다면 없애기도 함\n",
    "    - 사실 어떤 방식이 적합한지는 교차 검증을 통해 봐야 암"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특성 공학(Feature Engineering)\n",
    "- 모델이 수월하게 작업할 수 있게 데이터 형식을 만들어 주는 것\n",
    "- 피쳐를 어떻게 정리하냐에 따라 문제가 매우 간단해 질 수도(시계의 시간 읽기 모델 예시)\n",
    "- 딥러닝 이전에는 특성 공학이 매우 중요했음\n",
    "    - 전통적인 얕은 학습 방법들은 스스로 유용한 특성을 학습시킬 만한 넓은 hypothesis space를 가지고 있지 않음\n",
    "- 최근 딥러닝은 대부분 특성 공학이 필요 없음\n",
    "    - 뉴럴넷이 자동으로 유용한 특성 추출\n",
    "- 그렇다고 신경을 안쓰면 안됨\n",
    "    - 더 좋은 특성은 적은 자원을 사용해 문제를 더 멋지게 풀 수 있음\n",
    "    - 더 적은 데이터로 문제를 풀게 될 수도\n",
    "        - 스스로 특성을 뽑는 것은 데이터가 많을 때 얘기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting, Underfitting\n",
    "- 일반화(Generalization)은 새로운 데이터에 대해 얼마나 잘 수행되는지에 대한 것\n",
    "- 트레이닝 데이터, 검증 데이터에 대한 Loss가 모두 낮을 때 Underfitting\n",
    "    - 모델의 성능이 더 나아질 여지 있음\n",
    "    - 하지만 학습이 계속되면서 성능의 개선이 멈추기 시작 Overfitting\n",
    "        - 이제부터 트레이닝 데이터에 특화된 패턴을 학습하기 시작\n",
    "- Overfitting을 막는 가장 좋은 방법은\n",
    "    - 트레이닝 데이터를 많이 모으는 것\n",
    "    - 이게 안되면, 모델이 수용할 수 있는 정보의 양을 조절 혹은 제약을 가함\n",
    "        - 더 적은 패턴을 기억하도록 (더 중요한 패턴)\n",
    "        - 규제(Regularization)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규제(Regularization) \n",
    "- [참고자료](./deep-learning-with-python/4.4-overfitting-and-underfitting.ipynb)\n",
    "- **네트워크 크기 축소**\n",
    "    - 파라미터 수 줄이기 (capacity)\n",
    "    - 검증 Loss 가 감소할 때까지 늘려보기\n",
    "- 가중치 **규제** 추가\n",
    "    - 오컴의 면도날 ; 어떤 것에 대한 두 가지 설명이 잇따면 더 적은 가정이 필요한 간단한 설명이 옳을 것이다\n",
    "    - 간단한 모델이 복잡한 모델보다 오버피팅 될 가능성이 적다\n",
    "        - 여기서 간단한 모델이란 **파라미터 값의 분포의 엔트로피가 작은 모델 or 파라미터 수가 적은 모델**\n",
    "    - 가중치 규제(Weight Regularization)\n",
    "        - 네트워크의 Loss Function에 큰 가중치에 연관된 비용을 추가\n",
    "        - L1 규제: 가중치의 절댓값에 비례하는 비용\n",
    "        - L2 규제: 가중치의 제곱에 비례하는 비용 추가\n",
    "            - 가중치 감쇠(weight decay)라고도 부름\n",
    "            - l2(0.001)은 가중치 행렬의 모든 원소를 제곱하고 0.001을 곱해서 네트워크 전체 Loss에 더해짐(트레이닝 때만 추가)\n",
    "        ```py\n",
    "        from keras import regularizers\n",
    "        ...\n",
    "        model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                    activation='relu', input_shape=(10000,)))\n",
    "        # regularizers.l1(0.001), .l1_l2(l1=0.001, l2=0.001)\n",
    "        ```\n",
    "- **드롭아웃**\n",
    "    - 트레이닝 하는 동안 무작위로 레이어의 일부의 출력을 제외 시킴(0으로 만듬)\n",
    "    - 테스트 단계에선 모두 활용, but 드롭아웃 비율에 비례하게 층의 출력을 줄여준다\n",
    "        - 트레이닝 때보다 더 많은 유닛이 활성화 되므로\n",
    "    - 은행의 부정방지 메커니즘\n",
    "        - 업무를 자주 바꿈으로써 지구언들 사이의 유대를 낮춤\n",
    "    - 각 샘플에 대해 뉴런의 일부를 무작위로 제거해버리면 뉴런의 부정한 협업을 방지하고 오버피팅을 감소시킴\n",
    "        - [참고자료](https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/)\n",
    "        ```py\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝의 보편적인 작업 흐름\n",
    "1. 문제 정의 및 데이터셋 수집\n",
    "    - 시간에 따라 변하는 문제의 경우 주의(nonstationary problem)\n",
    "    - 머신러닝은 트레이닝 셋에있는 패턴만을 기억함\n",
    "        - 미래를 예측한 다는 것은 미래가 과거와 비슷하게 움직인다고 가정한 것일 뿐임\n",
    "2. 성공 지표 선택\n",
    "    - 정확도? 재현율? 정밀도?\n",
    "    - 성공 지표가 모델이 최적화할 Loss Function을 선택하는 기준이 됨\n",
    "    - 클래스 분포가 균일한 분류 문제\n",
    "        - 정확도 및 ROC AUC\n",
    "        - scikitlearn의 roc_auc_score, average_precision_score\n",
    "    - 클래스 분포가 균일하지 않은 문제\n",
    "        - 정밀도 및 재현율\n",
    "    - 랭킹 문제나 다중 레이블(한 샘플에 여러개 라벨 할당) 문제\n",
    "        - 평균 정밀도\n",
    "3. 평가 방법 선택\n",
    "    - 홀드아웃 검증 세트 분리\n",
    "        - 데이터가 풍부할 때만\n",
    "    - K-fold Cross Validation\n",
    "        - 홀드아웃 검증을 사용하기엔 샘플의 수가 너무 적을 때\n",
    "    - Iterated K-fold CV\n",
    "        - 데이터가 적고 매우 정확한 모델 평가가 필요할 때\n",
    "4. 데이터 준비\n",
    "    - 텐서로 만들기, 각 값은 작은 값으로 스케일 조정 (0~1, -1~1)\n",
    "    - 특성마다 범위가 다르면 정규화\n",
    "    - 데이터가 적을 경우엔 특성 공학(Feature Engineering)이 중요\n",
    "5. 기본보다 나은 모델 만들기\n",
    "    - 통계정 검정력(statistical power)을 가진 모델\n",
    "        - mnist에선 0.1보다 높은 정확도, imdb에선 0.5보다 높은 정확도를 갖는 모델\n",
    "    - 고려해야 할 것들\n",
    "        - 마지막 레이어의 Activation Function\n",
    "        - 풀려고 하는 문제의 종류에 적합한 Loss Function\n",
    "            - 손실 함수는 미니 배치에 대해 계산 가능하며 미분 가능해야 한다.\n",
    "        - 최적화 ; 어떤 optimizer, learning_rate, ...\n",
    "    - 자주 등장하는 유형에 따른 활성화 함수와 손실함수\n",
    "        - 이진 분류: sigmoid, binary_crossentropy\n",
    "        - 단일 레이블 다중 분류: softmax, categorical_crossentropy\n",
    "        - 다중 레이블 다중 분류: sigmoid, binary_crossentropy\n",
    "        - 임의 값 회귀: 없음, mse\n",
    "        - 0~1 값 회귀: sigmoid, mse or binary_crossentropy\n",
    "6. 몸집 키우기\n",
    "    - 머신러닝은 최적화와 일반화 사이의 줄다리기\n",
    "    - 층을 추가하고 크기를 키우며 더 많은 에포크 동안 트레이닝 하면서 오버피팅 모델까지 도달\n",
    "    - 적절한 지점 찾기\n",
    "7. 모델 규제 및 하이퍼파라미터 튜닝\n",
    "    - 반복적으로 모델 수정하며 검증 데이터를 이용해 평가 반복\n",
    "    - 적용해 볼것 들\n",
    "        - 드롭아웃\n",
    "        - 층 추가 및 제거, 다른 구조 시도\n",
    "        - L1, L2, or 둘다\n",
    "        - 층의 유닛 수 및 러닝 레이트 (hyperparams)\n",
    "        - feature engineering\n",
    "    - 테스트 세트의 성능이 검증 세트 성능보다 많이 나쁘면, 검증 과정에 신뢰성이 없거나 하이퍼파라미터 튜닝 과정에서 오버피팅 되버린 것\n",
    "        - 이런 경우 iterated k-fold CV 고려.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
